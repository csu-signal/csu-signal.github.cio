---
layout: page
title: About
permalink: /about/
---

<amp-img width="600" height="375" layout="responsive" src="../assets/images/diana.png"></amp-img>

The SIGNAL (**Si**tuated **G**rounding and **Na**tural **L**anguage) Lab studies language understanding and cognition from a computational perspective.  We tackle cutting-edge AI problems from a strongly multimodal perspective, welding computational linguistics and natural language processing with computer vision and cognitive systems.  We take a hybrid "neurosymbolic" approach that includes machine learning, logical reasoning, and simulation.  The SIGNAL Lab was spun out of the <a href="https://brandeis-llc.github.io">Lab for Linguistics and Computation</a> at Brandeis University and we collaborate heavily with other labs in the Colorado State Department of Computer Science, including the <a href="https://www.cs.colostate.edu/~draper/CwC.php">Communicating with Computers Lab</a> and the <a href="https://nuilab.org/Home">Natural User Interface Lab</a>.  The lab is directed by Prof. <a href="https://www.nikhilkrishnaswamy.com">Nikhil Krishnaswamy</a>.

### What is situated grounding?

<font size="3">"Grounding" refers to the process of giving a linguistic reference meaning by linking it to an actual entity (for example, the noun "cat" to an actual cat or the verb "run" to the act of running).  "Situated" here refers to the contextual model a person or computational agent creates of the situation/environment it inhabits, including what entities surround it, and what it can do in that environment.

This is a skill that humans excel at but that even the most sophisticated AI systems still struggle with.  Try asking your iPhone or Google Home, "What am I pointing at?"  Because these devices have no model of the surrounding environment, they can't answer the question!

"Situated grounding" is the process of giving symbols meaning by linking them to entities in the surrounding environment, It allows for a criital feature of language use: decontextualized reference, or the use of a symbol outside the situation where the linked entity is present.  That is, there doesn't need to be a cat in the room to talk about cats, as long as everyone understands what a cat is and what it does, which they most likely learned by seeing or interacting with a cat somewhere else.</font>

### What do we work on?

<font size="3">The term "situated grounding" was first used in the context of "situated grounding *problems*," or failures of intelligent systems to go just that. By merging natural language understanding to sophisticated environmental and simulation models, we develop solutions to these problems, allowing for natural and useful interactions with intelligent agents, large datasets, and robots.

This involves work in AI, including developing and deploying machine learning and neurosymbolic models; theoretical and corpus linguistcs, including semantic modeling and annotating data; and software engineering, including building and deploying real-time interactive architectures.</font>

### What are some projects?

<font size="3">Above is **Diana**, an intelligent interactive agent who understands spoken English and gestures to collaborate with a human in real time on construction tasks.  We also have ongoing work with navigating robots and multimodal data exploration.

Our primary platform is **VoxWorld**, which is built on the Unity game engine and **VoxML** a multimodal semantic modeling language that allows us to interpret language, gesture, and other modalities in a simulated environment. Individual implementations built on VoxWorld allow humans to communicate with intelligent agents such as Diana in ways that the agent's embodiment allows, be that manipulating virtual objects, or navigating a real space and finding objects.</font>

### Can I get involved?

<font size="3">If you are a current CSU student, feel free to <a href="contact">contact us</a>.  If you are not a current CSU student, you should <a href="https://admissions.colostate.edu">apply to the university</a>.</font>
