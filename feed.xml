<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>SIGNAL Lab</title>
    <description>Situated Grounding and Natural Language &lt;br/&gt; NLP @ CSU</description>
    <link>https://www.signallab.ai/https://www.signallab.ai//</link>
    <atom:link href="https://www.signallab.ai/https://www.signallab.ai//feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sun, 21 Jan 2024 22:57:19 +0000</pubDate>
    <lastBuildDate>Sun, 21 Jan 2024 22:57:19 +0000</lastBuildDate>
    <generator>Jekyll v3.8.5</generator>
    
      <item>
        <title>RETTL Grant Awarded</title>
        <description>&lt;p&gt;Pleased to announce that our grant proposal to NSF’s RETTL program, &lt;em&gt;An AI Tutoring System for Pollinator Conservation Community Science Training&lt;/em&gt;, has been awarded, for $849,890!&lt;/p&gt;

&lt;p&gt;This project is led by my colleague Dr. Sarath Sreedharan and includes Dr. Nate Blanchard of CSU’s Vision Lab and Dr. Jill Zarestky in the CSU School of Education.  In this project we will develop AI-powered tools for citizen science, focusing on identification of different pollinator species.  Let’s get them bees!&lt;/p&gt;
</description>
        <pubDate>Mon, 11 Sep 2023 07:00:00 +0000</pubDate>
        <link>https://www.signallab.ai/https://www.signallab.ai//rettl-grant-awarded</link>
        <guid isPermaLink="true">https://www.signallab.ai/https://www.signallab.ai//rettl-grant-awarded</guid>
        
        <category>lab</category>
        
        <category>news</category>
        
        <category>grants</category>
        
        
      </item>
    
      <item>
        <title>Spring 2023 Publication Round Up</title>
        <description>&lt;p&gt;At the end of the semester, time to take stock of lab activity:&lt;/p&gt;

&lt;p&gt;Hannah VanderHoeven’s paper &lt;em&gt;Robust Motion Recognition using Gesture Phase Annotation&lt;/em&gt; was accepted for publication at HCII 2023 in Copenhagen, Denmark in July!&lt;/p&gt;

&lt;p&gt;Also at HCII will be &lt;em&gt;Intentional Microgesture Recognition for Extended Human-Computer Interaction&lt;/em&gt;, with Sheikh Mannan and Hannah as contributing authors!&lt;/p&gt;

&lt;p&gt;Mariah Bradford and Ibrahim Khebour’s paper &lt;em&gt;Automatic Detection of Collaborative States in Small Groups Using Multimodal Features&lt;/em&gt; was accepted for publication at AIEd 2023 in Tokyo, Japan, also in July!&lt;/p&gt;

&lt;p&gt;Mariah and Ibrahim also contributed to &lt;em&gt;How Good is Automatic Segmentation as a Multimodal Discourse Annotation Aid?&lt;/em&gt;, accepted for presentation at the Interoperable Semantic Annotation workshop at IWCS in June.&lt;/p&gt;

&lt;p&gt;Sadaf Ghaffari’s paper &lt;em&gt;Grounding and Distinguishing Conceptual Vocabulary Through Similarity Learning in Embodied Simulations&lt;/em&gt; was accepted for publication at the IWCS 2023 main conference in Nancy, France!&lt;/p&gt;

&lt;p&gt;And finally, Abhijnan Nath and Mannan’s paper &lt;em&gt;AxomiyaBERTa: A Phonologically-aware Transformer Model for Assamese&lt;/em&gt; was accepted for publication in Findings of ACL 2023, the companion volume to the ACL 2023 conference!  Abhijnan was also second author on &lt;em&gt;2*n is better than n^2: Decomposing Event Coreference Resolution into Two Tractable Problems&lt;/em&gt;, a collaboration with members of the BoulderNLP group, also accepted to Finding of ACL 2023.  ACL 2023 will be held in Toronto, ON, Canada, in July.&lt;/p&gt;

&lt;p&gt;Look out for these papers, and more to come soon.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Citations&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;VanderHoeven, H., Blanchard, N., and Krishnaswamy, N. (2023). &lt;em&gt;Robust Motion Recognition using Gesture Phase Annotation.&lt;/em&gt; In &lt;em&gt;International Conference on Human-Computer Interaction (HCII)&lt;/em&gt;. Springer.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Kandoi, C., Jung, C., Mannan, S., VanderHoeven, H., Meisman, Q., Krishnaswamy, N., and Blanchard, N. (2023). &lt;em&gt;Intentional Microgesture Recognition for Extended Human-Computer Interaction.&lt;/em&gt; In &lt;em&gt;International Conference on Human-Computer Interaction (HCII)&lt;/em&gt;. Springer.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Bradford, M., Khebour, I., Blanchard, N., and Krishnaswamy, N. (2023). &lt;em&gt;Automatic Detection of Collaborative States in Small Groups Using Multimodal Features.&lt;/em&gt; In &lt;em&gt;International Conference on Artificial Intelligence in Education (AIEd)&lt;/em&gt;. International AIEd Society.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Terpstra, C., Khebour, I., Bradford, M., Wisniewski, B., Krishnaswamy, N., and Blanchard, N. (2023). &lt;em&gt;How Good is Automatic Segmentation as a Multimodal Discourse Annotation Aid?&lt;/em&gt; In &lt;em&gt;International Workshop on Semantic Annotation (ISA)&lt;/em&gt;. ACL.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ghaffari, S. and Krishnaswamy, N. (2023). &lt;em&gt;Grounding and Distinguishing Conceptual Vocabulary Through Similarity Learning in Embodied Simulations.&lt;/em&gt; In &lt;em&gt;International Conference on Computational Semantics (IWCS)&lt;/em&gt;. ACL.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Nath, A., Mannan, S., and Krishnaswamy, N. (2023). &lt;em&gt;AxomiyaBERTa: A Phonologically-aware Transformer Model for Assamese.&lt;/em&gt; In &lt;em&gt;Findings of the Association for Computational Linguistics (Findings of ACL)&lt;/em&gt;. ACL.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ahmed, S. R., Nath, A., Martin, J. H., and Krishnaswamy, N. (2023). &lt;em&gt;2*n is better than n^2: Decomposing Event Coreference Resolution into Two Tractable Problems.&lt;/em&gt; In &lt;em&gt;Findings of the Association for Computational Linguistics (Findings of ACL)&lt;/em&gt;. ACL.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 14 May 2023 07:00:00 +0000</pubDate>
        <link>https://www.signallab.ai/https://www.signallab.ai//spring-2023-publication-roundup</link>
        <guid isPermaLink="true">https://www.signallab.ai/https://www.signallab.ai//spring-2023-publication-roundup</guid>
        
        <category>lab</category>
        
        <category>news</category>
        
        <category>pubs</category>
        
        
      </item>
    
      <item>
        <title>Congratulations to Aniket Tomar!</title>
        <description>&lt;p&gt;Congratulations to &lt;strong&gt;Aniket Tomar&lt;/strong&gt; on successfully defending his Master’s thesis!&lt;/p&gt;

&lt;p&gt;Aniket’s thesis is entitled &lt;em&gt;Exploring Correspondences Between Gibsonian and Telic Affordances for Object Grasping using 3D Geometry&lt;/em&gt;. This is a really interesting work in that Aniket took what was initially a negative result and probed it enough to draw a robust conclusion about the representation of Gibsonian and telic affordaces in 3D data and the difficulty of embodied tasks for even specialized machine learning models. Part of this work appeared in our &lt;a href=&quot;https://www.nikhilkrishnaswamy.com/assets/docs/pdfs/AREA-2022.pdf&quot;&gt;AREA workshop paper&lt;/a&gt; at ESSLLI last summer.&lt;/p&gt;

&lt;p&gt;Congratulations to Aniket!  It’s been a pleasure working with you and I look forward to seeing what you do next!&lt;/p&gt;

&lt;p&gt;Here we are after the defense with Aniket’s committee: myself, Prof. Nathaniel Blanchard and Prof. Ben Clegg from Psychology.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/spring23/aniket-defense.jpg?raw=true&quot; alt=&quot;Aniket Tomar MS Thesis Defense&quot; title=&quot;Aniket Tomar MS Thesis&quot; /&gt;&lt;/p&gt;

&lt;p&gt;(X-posted on &lt;a href=&quot;https://www.nikhilkrishnaswamy.com/2023/03/06/congratulations-aniket-tomar.html&quot;&gt;nikhilkrishnaswamy.com&lt;/a&gt;)&lt;/p&gt;
</description>
        <pubDate>Mon, 06 Mar 2023 07:00:00 +0000</pubDate>
        <link>https://www.signallab.ai/https://www.signallab.ai//congratulations-aniket-tomar</link>
        <guid isPermaLink="true">https://www.signallab.ai/https://www.signallab.ai//congratulations-aniket-tomar</guid>
        
        <category>lab</category>
        
        <category>news</category>
        
        <category>grads</category>
        
        
      </item>
    
      <item>
        <title>New Paper at ACS</title>
        <description>&lt;p&gt;SIGNAL Lab Ph.D. student Sadaf Ghaffari presented &lt;em&gt;Detecting and Accommodating Novel Types and Concepts in an Embodied Simulation Environment&lt;/em&gt; at the Annual Conference on Advances in Cognitive Systems at George Mason University in Arlington, VA.  In this paper, we explore techniques to imbue neural networks with the capability to expand to accommodate new concepts and to detect when the neural model itself is inadequate to the environment, relying on information extracted from an embodied simulation.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Citations&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ghaffari, S. and Krishnaswamy, N. (2022). &lt;em&gt;Detecting and Accommodating Novel Types and Concepts in an Embodied Simulation Environment.&lt;/em&gt; In &lt;em&gt;Annual Conference on Advances in Cognitive Systems (ACS)&lt;/em&gt;. Cognitive Systems Foundation.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Mon, 21 Nov 2022 07:00:00 +0000</pubDate>
        <link>https://www.signallab.ai/https://www.signallab.ai//new-paper-at-acs-2022</link>
        <guid isPermaLink="true">https://www.signallab.ai/https://www.signallab.ai//new-paper-at-acs-2022</guid>
        
        <category>lab</category>
        
        <category>news</category>
        
        <category>pubs</category>
        
        
      </item>
    
      <item>
        <title>Congrats to Fall '22 M.S. Project Presenters</title>
        <description>&lt;p&gt;Congratulations to M.S. students Ramya Sree Patchava and Kush Pandya who presented their M.S. Project posters at the CSU CS Graduate Research Symposium yesterday!&lt;/p&gt;

&lt;p&gt;Very proud to see these two bring their research to a successful conclusion and graduate!&lt;/p&gt;

&lt;p&gt;Ramya’s project: &lt;strong&gt;Evaluating Interchangeability of Face Feature Vectors&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Kush’s project: &lt;strong&gt;Qualitative Spatial Relation Representation with ML Embedding Spaces&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Here we are at the conclusion of yesterday’s event:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/fall22/posters-ramya-kush.jpg?raw=true&quot; alt=&quot;Ramya and Kush's Posters&quot; title=&quot;Ramya and Kush's Posters&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 21 Oct 2022 07:00:00 +0000</pubDate>
        <link>https://www.signallab.ai/https://www.signallab.ai//fall-22-ms-project-posters</link>
        <guid isPermaLink="true">https://www.signallab.ai/https://www.signallab.ai//fall-22-ms-project-posters</guid>
        
        <category>lab</category>
        
        <category>news</category>
        
        <category>grads</category>
        
        
      </item>
    
      <item>
        <title>Congratulations to Abhijnan Nath!</title>
        <description>&lt;p&gt;Congratulations to &lt;strong&gt;Abhijnan Nath&lt;/strong&gt; for defending his Master’s thesis!&lt;/p&gt;

&lt;p&gt;Abhijnan’s thesis is entitled &lt;em&gt;Linear Mappings: Semantic Transfer from Transformer Models for Cognate Detection and Coreference Resolution&lt;/em&gt;. Abhijnan argues that high-dimensional vector semantic information can be transfered between Transformer-based language models using a simple affine transformation technique that draws upon previous insights from vision researchers from CSU. He presents evidence from two distinct linguistic tasks: bilingual cognate detection and cross-document coreference eresolution. Part of this research appears in our VarDial workship paper from COLING this year and part of it was funded by the DARPA AIDA program.  Abhijnan will be continuing in the SIGNAL Lab for a Ph.D. starting in Fall 2022!&lt;/p&gt;

&lt;p&gt;Congratulations to Abhijnan!  It’s been a pleasure to work with you and I look forward to continuing our collaboration!&lt;/p&gt;

&lt;p&gt;Here we are after the defense with Abhijnan’s external committee member, Prof. Emily King from Mathematics.  Not shown: Prof. Nate Blanchard, who was out of town and attended remotely.  Getting a student to photoshop him in.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/fall22/abhijnan-defense.jpg?raw=true&quot; alt=&quot;Abhijnan Nath MS Thesis Defense&quot; title=&quot;Abhijnan Nath MS Thesis&quot; /&gt;&lt;/p&gt;

&lt;p&gt;(X-posted on &lt;a href=&quot;https://www.nikhilkrishnaswamy.com/2022/10/21/congratulations-abhijnan-nath.html&quot;&gt;nikhilkrishnaswamy.com&lt;/a&gt;)&lt;/p&gt;
</description>
        <pubDate>Fri, 21 Oct 2022 07:00:00 +0000</pubDate>
        <link>https://www.signallab.ai/https://www.signallab.ai//congratulations-abhijnan-nath</link>
        <guid isPermaLink="true">https://www.signallab.ai/https://www.signallab.ai//congratulations-abhijnan-nath</guid>
        
        <category>lab</category>
        
        <category>news</category>
        
        <category>grads</category>
        
        
      </item>
    
      <item>
        <title>Summer/Fall Publications</title>
        <description>&lt;p&gt;It’s been a busy summer!&lt;/p&gt;

&lt;p&gt;In addition to the publications mentioned previously (&lt;em&gt;The VoxWorld Platform for Multimodal Embodied Agents&lt;/em&gt;, &lt;em&gt;Exploiting Embodied Simulation to Detect Novel Object Classes Through Interaction&lt;/em&gt;, and &lt;em&gt;A deep dive into microphones for recording collaborative group work&lt;/em&gt;), members of the SIGNAL Lab were involved with a slew of other papers that were presented during the summer or will be in the fall:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Challenges and Opportunities in Annotating a Multimodal Collaborative Problem Solving Task&lt;/em&gt; and &lt;em&gt;Multimodal Features for Group Dynamic-Aware Agents&lt;/em&gt; were presented by SIGNAL Lab Ph.D. student Mariah Bradford at the Workshop on Interdisciplinary Approaches to Getting AI Experts and Education Stakeholders Talking (Bridging AIEd) at AIEd in Durham, UK, in late July. These papers address questions in feature extraction and annotation in small group tasks for the NSF AI Institute for Student-AI Teaming (iSAT).&lt;/p&gt;

&lt;p&gt;&lt;em&gt;iSAT speech-based AI display for small group collaboration in classrooms&lt;/em&gt; won the Best Interactive Event Award at AIEd! SIGNAL Lab Ph.D. student Ibrahim Khebour worked on this demo for iSAT.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Exploring Correspondences Between Gibsonian and Telic Affordances for Object Grasping&lt;/em&gt; was presented at the 2nd Workshop on Annotation, Recognition and Evaluation of Actions (AREA) at ESSLLI in Galway, Ireland in early August. This paper is adapted from part of Aniket Tomar’s Master’s thesis work on grasping affordances.&lt;/p&gt;

&lt;p&gt;Ph.D. student Sheikh Mannan’s paper &lt;em&gt;Where am I and where should I go? Grounding positional and directional labels in a disoriented human balancing task&lt;/em&gt; applies AI and language models to a novel task involving a sophisiticated notion of embodiment.  It will be presented at the Conference on (Dis)embodiment, hosted by the Centre for Linguistic Theory and Studies in Probability (CLASP) at the University of Gothenburg in Sweden on September 16.&lt;/p&gt;

&lt;p&gt;Finally, &lt;em&gt;A Generalized Method for Automated Multilingual Loanword Detection&lt;/em&gt; will appear as a poster at COLING 2022 in Gyeongju, Korea in October. This paper was a true team effort by researchers Abhijnan Nath, Sina Mahdipour Saravani, Ibrahim Khebour, Sheikh Mannan, and Zihui Li, in which we present a novel approach to detecting loanwords across arbitrary language pairs. Its companion paper &lt;em&gt;Phonetic, Semantic, and Articulatory Features in Assamese-Bengali Cognate Detection&lt;/em&gt;, led by Abhijnan, will be presented at the associated Workshop on NLP for Similar Languages, Varieties, and Dialects (VarDial).&lt;/p&gt;

&lt;p&gt;Congratulations to all these students, and many others who have work under review or in preparation!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Citations&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Bradford, M., Hansen, P., Lai, K., Brutti, R., Dickler, R., Hirshfield, L. M., Pustejovsky, J., Blanchard, N., and Krishnaswamy, N. (2022). &lt;em&gt;Challenges and Opportunities in Annotating a Multimodal Collaborative Problem Solving Task.&lt;/em&gt; In &lt;em&gt;Workshop on Interdisciplinary Approaches to Getting AI Experts and Education Stakeholders Talking (Bridging AIEd)&lt;/em&gt;. International AIEd Society.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Castillon, I., Venkatesha, V., VanderHoeven, H., Bradford, M., Krishnaswamy, N., and Blanchard, N. (2022). &lt;em&gt;Multimodal Features for Group Dynamic-Aware Agents.&lt;/em&gt; In &lt;em&gt;Workshop on Interdisciplinary Approaches to Getting AI Experts and Education Stakeholders Talking (Bridging AIEd)&lt;/em&gt;. International AIEd Society.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Dickler, R., Foltz, P. W., Krishnaswamy, N., Whitehill, J., Weatherly, J., Bodzianowski, M., Perkoff, M., Southwell, R., Pugh, S., Bush, J., Chang, M., Hirshfield, L. M., Showers, D., Ganesh, A., Li, Z., Danilyuk, E., He, X., Khebour, I., Dey, I., Puntambekar, S., and D’Mello, S. K. (2022). &lt;em&gt;iSAT speech-based AI display for small group collaboration in classrooms&lt;/em&gt;. In Interactive event at International Conference on Artificial Intelligence in Education (AIEd). International AIEd Society.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Tomar, A. and Krishnaswamy, N. (2022). &lt;em&gt;Exploring Correspondences Between Gibsonian and Telic Affordances for Object Grasping.&lt;/em&gt; In &lt;em&gt;Workshop on Annotation, Recognition and Evaluation of Actions (AREA)&lt;/em&gt;. ACL.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Mannan, S. and Krishnaswamy, N. (2022). &lt;em&gt;Where am I and where should I go? Grounding positional and directional labels in a disoriented human balancing task.&lt;/em&gt; &lt;em&gt;In Conference on (Dis)embodiment&lt;/em&gt;. ACL.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Nath, A., Mahdipour Saravani, S., Khebour, I., Mannan, S., Li, Z., and Krishnaswamy, N. (2022). &lt;em&gt;A Generalized Method for Automated Multilingual Loanword Detection.&lt;/em&gt; In &lt;em&gt;International Conference on Computational Linguistics (COLING)&lt;/em&gt;. ACL.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Nath, A., Ghosh, R., and Krishnaswamy, N. (2022). &lt;em&gt;Phonetic, Semantic, and Articulatory Features in Assamese-Bengali Cognate Detection.&lt;/em&gt; In &lt;em&gt;Workshop on NLP for Similar Languages, Varieties, and Dialects (VarDial)&lt;/em&gt;. ACL.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Thu, 08 Sep 2022 07:00:00 +0000</pubDate>
        <link>https://www.signallab.ai/https://www.signallab.ai//summer-fall-publications</link>
        <guid isPermaLink="true">https://www.signallab.ai/https://www.signallab.ai//summer-fall-publications</guid>
        
        <category>lab</category>
        
        <category>news</category>
        
        <category>pubs</category>
        
        
      </item>
    
      <item>
        <title>3 New Publications</title>
        <description>&lt;p&gt;Three upcoming publications:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;The VoxWorld Platform for Multimodal Embodied Agents&lt;/em&gt; will be a poster and demo, and published in the proceedings of the Language Resources and Evaluation Conference (LREC) in Marseille, France, in June.  This publication is a 5-year retrospective on the VoxWorld platform and presents 3 of the agents developed with it.  This paper was written with multiple collaborators including future SIGNAL Lab Ph.D. student Brittany Cates.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Krishnaswamy, N., Pickard, W., Cates, B., Blanchard, N., and Pustejovsky, J. (2022). &lt;em&gt;The VoxWorld Platform for Multimodal Embodied Agents&lt;/em&gt;. In &lt;em&gt;Language Resources and Evaluation Conference&lt;/em&gt; (LREC).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;Exploiting Embodied Simulation to Detect Novel Object Classes Through Interaction&lt;/em&gt; will be a poster at the Annual Meeting of the Cognitive Science Society in Toronto, ON, Canada, in July.  This publication presents early zero-shot transfer learning work based on object interactions with SIGNAL Lab Ph.D. student Sadaf Ghaffari.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Krishnaswamy, N., and Ghaffari, S. (2022). &lt;em&gt;Exploiting Embodied Simulation to Detect Novel Object Classes Through Interaction&lt;/em&gt;. In &lt;em&gt;Annual Meeting of the Cognitive Science Society&lt;/em&gt; (CogSci).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;A deep dive into microphones for recording collaborative group work&lt;/em&gt; will be a poster and short paper at the International Conference on Educational Data Mining (EDM) in Durham, England, in July.  In this paper we examine the effects of various audio hardware stacks on downstream educational data mining tasks such as speech recognition.  This paper was written with many collaborators at CSU including future SIGNAL Lab Ph.D. student Mariah Bradford.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Bradford, M., Hansen, P., Beveridge, R., Krishnaswamy, N., and Blanchard, N. (2022). &lt;em&gt;A deep dive into microphones for recording collaborative group work&lt;/em&gt;. In &lt;em&gt;International Conference on Educational Data Mining&lt;/em&gt; (EDM).&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 17 Apr 2022 07:00:00 +0000</pubDate>
        <link>https://www.signallab.ai/https://www.signallab.ai//3-new-publications</link>
        <guid isPermaLink="true">https://www.signallab.ai/https://www.signallab.ai//3-new-publications</guid>
        
        <category>lab</category>
        
        <category>news</category>
        
        <category>pubs</category>
        
        
      </item>
    
      <item>
        <title>Congratulations to Dhruva Patil and Jason Garcia!</title>
        <description>&lt;p&gt;Congratulations to Dr. &lt;strong&gt;Dhruva Patil&lt;/strong&gt; for defending his Ph.D. dissertation and to &lt;strong&gt;Jason Garcia&lt;/strong&gt; for defending his Master’s thesis!&lt;/p&gt;

&lt;p&gt;Dhruva’s dissertation is entitled &lt;em&gt;Something Is Fishy! How ambiguous language affects generalization of video action recognition networks&lt;/em&gt;. In this research, he analyses weaknesses in the label set of the popular Something-Something video action recognition dataset, and discusses how the one-hot encoding of class labels in computer vision tasks may effectively be hamstringing deep neural networks in vision tasks.  Dhruva will be starting a research position at Amazon in June.&lt;/p&gt;

&lt;p&gt;Jason’s thesis is entitled &lt;em&gt;Applications of Topological Data Analysis to Natural Language Processing and Computer Vision&lt;/em&gt;. Jason applies techniques of topological data analysis, a mathematical technique for exploring the “shape” of data, to problems in NLP and computer vision, including a novel analysis of the topological properties of the encoder layers in BERT.  Jason will be continuing at CSU for a Ph.D. in Math.&lt;/p&gt;

&lt;p&gt;Congratulations to Dhruva and Jason!  It’s been a pleasure to work with you and to see you acheive your degrees!&lt;/p&gt;

&lt;p&gt;(X-posted on &lt;a href=&quot;https://www.nikhilkrishnaswamy.com/2022/04/11/congratulations-dhruva-patil-jason-garcia.html&quot;&gt;nikhilkrishnaswamy.com&lt;/a&gt;)&lt;/p&gt;
</description>
        <pubDate>Mon, 11 Apr 2022 07:00:00 +0000</pubDate>
        <link>https://www.signallab.ai/https://www.signallab.ai//congratulations-dhruva-patil-jason-garcia</link>
        <guid isPermaLink="true">https://www.signallab.ai/https://www.signallab.ai//congratulations-dhruva-patil-jason-garcia</guid>
        
        <category>lab</category>
        
        <category>news</category>
        
        <category>grads</category>
        
        
      </item>
    
      <item>
        <title>Congrats to M.S. Project Presenters</title>
        <description>&lt;p&gt;Congratulations to M.S. students Shivani Mogullapalli, Shriram Gaddam, and Mohit Kumar Katragadda who presented their M.S. Project posters at the CSU CS Graduate Research Symposium yesterday!&lt;/p&gt;

&lt;p&gt;CSU Computer Science has a non-thesis research initiation option for master’s students wherein the student must conduct a research project under the guidance of a faculty member and present a poster on their project in their last semester.  Very proud of the work these three have done this semester and I can wait to see them wrap up the work and graduate!&lt;/p&gt;

&lt;p&gt;Mohit’s project: &lt;strong&gt;Distributed Training of 3D Object Recognition Using Point Clouds&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Shivani’s project: &lt;strong&gt;Mapping Between Face Recogniton Feature Vector from Various CNN Models&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Shriram’s project: &lt;strong&gt;Exploring Embedding Spaces in Transformers by Mapping Feature Vectors&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Some pics from yesterday’s event are below:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/fall21/poster-shriram.jpg?raw=true&quot; alt=&quot;Exploring Embedding Spaces in Transformers by Mapping Feature Vectors&quot; title=&quot;Exploring Embedding Spaces in Transformers by Mapping Feature Vectors&quot; /&gt;&lt;img src=&quot;../assets/images/fall21/poster-mohit.jpg?raw=true&quot; alt=&quot;Distributed Training of 3D Object Recognition Using Point Clouds&quot; title=&quot;Distributed Training of 3D Object Recognition Using Point Clouds&quot; /&gt;&lt;img src=&quot;../assets/images/fall21/poster-shivani.jpg?raw=true&quot; alt=&quot;Mapping Between Face Recogniton Feature Vector from Various CNN Models&quot; title=&quot;Mapping Between Face Recogniton Feature Vector from Various CNN Models&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 30 Oct 2021 07:00:00 +0000</pubDate>
        <link>https://www.signallab.ai/https://www.signallab.ai//ms-project-posters</link>
        <guid isPermaLink="true">https://www.signallab.ai/https://www.signallab.ai//ms-project-posters</guid>
        
        <category>lab</category>
        
        <category>news</category>
        
        <category>grads</category>
        
        
      </item>
    
  </channel>
</rss>
